{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CS6910-Assignment2-PartB",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1g4V4zVtJRtc5SGV_WWAeN3HtheXcdyee",
      "authorship_tag": "ABX9TyN58eAu63ZexiejnmjIWYDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safikhanSoofiyani/CS6910-Assignment-2/blob/main/CS6910_Assignment2_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS6910-Assignment2-Part B\n",
        "Using Pretrained model for Image Classification"
      ],
      "metadata": {
        "id": "XDeU2CS7WZMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
      ],
      "metadata": {
        "id": "XZS6Eod-WCXU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    #path=r\"C:\\Users\\vamsi_oe20s302\\Downloads\\nature_12K\\inaturalist_12K\\train\"\n",
        "    path=r\"/content/drive/MyDrive/nature_12K/inaturalist_12K/train\"\n",
        "\n",
        "    # Training dataset:\n",
        "    train_dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory=path,\n",
        "        labels='inferred',\n",
        "        label_mode='categorical',\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        image_size=(256,256),\n",
        "        shuffle=True,\n",
        "        seed=19,\n",
        "        validation_split=0.1,\n",
        "        subset='training'\n",
        "    )\n",
        "    # Validation dataset:\n",
        "    valid_dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory=path,\n",
        "        labels='inferred',\n",
        "        label_mode='categorical',\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        image_size=(256,256),\n",
        "        shuffle=True,\n",
        "        seed=19,\n",
        "        validation_split=0.1,\n",
        "        subset='validation'\n",
        "    )\n",
        "    \n",
        "    #return train_data, valid_data\n",
        "    return train_dataset, valid_dataset\n"
      ],
      "metadata": {
        "id": "84oe-Pu4Wv2R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_augmented_data():\n",
        "    #path=r\"C:\\Users\\vamsi_oe20s302\\Downloads\\nature_12K\\inaturalist_12K\\train\"\n",
        "    path=r\"/content/drive/MyDrive/nature_12K/inaturalist_12K/train\"\n",
        "    training_data_augmentation=ImageDataGenerator(rescale=1./255,\n",
        "                                        height_shift_range=0.2,\n",
        "                                        width_shift_range=0.2,\n",
        "                                        horizontal_flip=True,\n",
        "                                        zoom_range=0.2,\n",
        "                                        fill_mode=\"nearest\",\n",
        "                                        validation_split = 0.1)\n",
        "\n",
        "    # Validation data is not being augmented\n",
        "    validation_data_augmentation=ImageDataGenerator(\n",
        "        validation_split=0.1\n",
        "    )\n",
        "\n",
        "    train_aug=training_data_augmentation.flow_from_directory(path,shuffle=True,seed=19,subset='training')\n",
        "    valid_aug=validation_data_augmentation.flow_from_directory(path,shuffle=True,seed=19,subset='validation')\n",
        "\n",
        "    return train_aug, valid_aug\n"
      ],
      "metadata": {
        "id": "Yg42DuXIYOJu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning \n",
        "1. Reference 1: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "2. Reference 2: https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751"
      ],
      "metadata": {
        "id": "YoqX0f_03oIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inceptionv3(image_shape):\n",
        "  model=tf.keras.applications.InceptionV3(input_shape=image_shape,\n",
        "                                          include_top=False,\n",
        "                                          weights='imagenet')\n",
        "  return model\n",
        "\n",
        "def resnet50(image_shape):\n",
        "  model=tf.keras.applications.ResNet50(input_shape=image_shape,\n",
        "                                      include_top=False,\n",
        "                                      weights='imagenet')\n",
        "  return model\n",
        "\n",
        "def inceptionresnetv2(image_shape):\n",
        "  model=tf.keras.applications.InceptionResNetV2(input_shape=image_shape,\n",
        "                                                include_top=False,\n",
        "                                                weights='imagenet')\n",
        "  return model\n",
        "\n",
        "def xception(image_shape):\n",
        "  model=tf.keras.applications.Xception(input_shape=image_shape,\n",
        "                                      include_top=False,\n",
        "                                      weights='imagenet')\n",
        "  return model\n",
        "\n",
        "def transferlearning_model(name,dense_units,dropout,freeze_percent,batch_norm):\n",
        "  \n",
        "  image_shape=(256,256,3)\n",
        "  # calculating the number of layers in each model, and then freezing those layers\n",
        "  # freezing ensures that those layers are not trained, to maintain the generality\n",
        "\n",
        "  if name  == \"InceptionV3\":\n",
        "    model=inceptionv3(image_shape)\n",
        "    num_layers=len(model.layers)\n",
        "    k=math.ceil(freeze_percent*num_layers)\n",
        "    \n",
        "  elif name == \"InceptionResNetV2\":\n",
        "    model=inceptionresnetv2(image_shape)\n",
        "    num_layers=len(model.layers)\n",
        "    k=math.ceil(freeze_percent*num_layers)\n",
        "  \n",
        "  elif name == \"ResNet50\":\n",
        "    model=resnet50(image_shape)\n",
        "    num_layers=len(model.layers)\n",
        "    k=math.ceil(freeze_percent*num_layers)\n",
        "\n",
        "  elif name == \"Xception\":\n",
        "    model=xception(image_shape)\n",
        "    num_layers=len(model.layers)\n",
        "    k=math.ceil(freeze_percent*num_layers)\n",
        "  \n",
        "  else:\n",
        "    print(\"Enter a valid model name\")\n",
        "\n",
        "  # Freezing the k layers, making them un trainable\n",
        "  i=0\n",
        "  for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "    i=i+1\n",
        "    if(i==k):\n",
        "      break\n",
        "\n",
        "  # Adding a dense layer on top of the convolution layers.\n",
        "  a=layers.Flatten()(model.output)\n",
        "  a=layers.Dense(dense_units,layers.ReLU())(a)\n",
        "  if batch_norm:\n",
        "    a=layers.BatchNormalization()(a)\n",
        "  a=layers.Dropout(dropout)(a)\n",
        "  a=layers.Dense(10,tf.nn.softmax)(a)\n",
        "\n",
        "  final_model=Model(model.input,a)\n",
        "  \n",
        "  return final_model"
      ],
      "metadata": {
        "id": "tztUZpKvAcNo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=transferlearning_model(\"InceptionV3\",32,0.2,0.6,True)"
      ],
      "metadata": {
        "id": "HpbH7rccHCC9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb Sweeping"
      ],
      "metadata": {
        "id": "I3AXG0drY4_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters={\n",
        "    'model_name':{'values': [\"InceptionV3\",\"InceptionResNetV2\",\"ResNet50\",\"Xception\"]},\n",
        "    'data_augmentation':{'values':[False,True]},\n",
        "    'batch_normalization':{'values':[False,True]},\n",
        "    'freeze_percent':{'values':[0.6,0.7,0.8,0.9,1.0]},\n",
        "    'dense_units':{'values':[32,64,128]},\n",
        "    'dropout_final_layer':{'values':[0.2,0.3,0.4,0.5]},\n",
        "    'learning_rate':{'values':[0.001,0.00001,0.0005]}\n",
        "}\n",
        "sweep_config = {\n",
        "      'method' : 'bayes',\n",
        "      'metric' :{\n",
        "          'name': 'val_acc',\n",
        "          'goal': 'maximize'\n",
        "      },\n",
        "      'parameters': hyperparameters\n",
        "    }"
      ],
      "metadata": {
        "id": "t-HGyE98MgEX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_train(config=sweep_config):\n",
        "  # initializing wandb with the above configuration\n",
        "  wandb.init(config=config)\n",
        "  \n",
        "  # collecting the configuration information\n",
        "  config=wandb.init().config\n",
        "  \n",
        "  # setting up the name for each run example : Model_Xception_tune_False_aug_True\n",
        "  run_name='Model_{}_freeze_percent_{}_Data_aug_{}_lr_{}_dropout_{}_dense_units_{}_batch_norm_{}'.format(config.model_name,\n",
        "                                                                             config.freeze_percent,\n",
        "                                                                             config.data_augmentation,\n",
        "                                                                             config.learning_rate,\n",
        "                                                                             config.dropout_final_layer,\n",
        "                                                                             config.dense_units,\n",
        "                                                                             config.batch_normalization                                                                            \n",
        "                                                                             )\n",
        "  wandb.run.name=run_name\n",
        "\n",
        "  # caling the model \n",
        "  model=transferlearning_model(config.model_name,\n",
        "                               config.dense_units,\n",
        "                               config.dropout_final_layer,\n",
        "                               config.freeze_percent,\n",
        "                               config.batch_normalization)\n",
        "\n",
        "  learning_rate=config.learning_rate\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  # Getting data \n",
        "  train_data,val_data=get_data()\n",
        "  train_aug_data,val_aug_data=get_augmented_data()\n",
        "\n",
        "  if config.data_augmentation == False:\n",
        "    history = model.fit(train_data, epochs=10, validation_data=val_data,\n",
        "                        callbacks = [wandb.keras.WandbCallback()])\n",
        "  else:\n",
        "    history = model.fit(train_aug_data, steps_per_epoch=62, epochs=10,\n",
        "                        validation_data=val_aug_data, validation_steps=62,\n",
        "                        workers=10, callbacks = [wandb.keras.WandbCallback()])  \n",
        "  \n",
        "  wandb.run.finish()"
      ],
      "metadata": {
        "id": "4GoC1CH3Z2FT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin\n",
        "entity_name = \"safi-vamsi-cs6910\"\n",
        "project_name = \"Assignment 2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efQ1LFtzXsaE",
        "outputId": "7c9e4a30-9248-4162-f860-dc52879f7f0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id=wandb.sweep(sweep_config,entity=entity_name,project=project_name)\n",
        "wandb.agent(sweep_id,wandb_train)"
      ],
      "metadata": {
        "id": "rlAWhNabdYi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wz5xILMke0oZ"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}